{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cede148e-0721-4693-b2aa-22b6ad4fb7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio.Data.IUPACData import protein_letters_3to1\n",
    "import re\n",
    "import os\n",
    "import db_utils\n",
    "import sqlalchemy\n",
    "from find_path import find_file\n",
    "from collections import OrderedDict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b508f21-1ce4-4f78-8ac8-fade3c7693f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the input for uniprot mapping from clinvar:\n",
    "# refseq = clinvar['RefSeq_ID'].to_frame()\n",
    "# refseq.drop_duplicates(inplace=True)\n",
    "# refseq.to_csv('refseqIDs.txt', sep='\\n', header= False, index = False)\n",
    "\n",
    "# in uniprot, I used from RefSeq Nucleotide to UniProtKB mapping and just added one column from external resources and then genome annotation: ensebml, from where I extracted the uniprot isoform information\n",
    "\n",
    "# get the output\n",
    "# mapping = pd.read_csv('RefSeqToUniProt.tsv', sep='\\t')\n",
    "# mapping.rename(columns={'From':'RefSeq_ID', 'Entry':'uni_AC'}, inplace=True)\n",
    "\n",
    "# # extract isoform ID from the ensembl column\n",
    "# pattern = r'\\[([^\\]]+)\\]'\n",
    "# matches = mapping['Ensembl'].str.extractall(pattern)\n",
    "# result = matches.groupby(level=0)[0].apply(list)\n",
    "# mapping['Ref_Seq_to_iso'] = result\n",
    "# mapping = mapping[['RefSeq_ID','uni_AC','Ref_Seq_to_iso']]\n",
    "# mapping = mapping.explode('Ref_Seq_to_iso')\n",
    "# mapping.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede54c3a-57ab-4ea6-a38f-c1cdcce9ba79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AlleleID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>GeneID</th>\n",
       "      <th>GeneSymbol</th>\n",
       "      <th>HGNC_ID</th>\n",
       "      <th>ClinicalSignificance</th>\n",
       "      <th>ClinSigSimple</th>\n",
       "      <th>LastEvaluated</th>\n",
       "      <th>RS# (dbSNP)</th>\n",
       "      <th>...</th>\n",
       "      <th>ReviewStatus</th>\n",
       "      <th>NumberSubmitters</th>\n",
       "      <th>Guidelines</th>\n",
       "      <th>TestedInGTR</th>\n",
       "      <th>OtherIDs</th>\n",
       "      <th>SubmitterCategories</th>\n",
       "      <th>VariationID</th>\n",
       "      <th>PositionVCF</th>\n",
       "      <th>ReferenceAlleleVCF</th>\n",
       "      <th>AlternateAlleleVCF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15041</td>\n",
       "      <td>Indel</td>\n",
       "      <td>NM_014855.3(AP5Z1):c.80_83delinsTGCTGTAAACTGTA...</td>\n",
       "      <td>9907</td>\n",
       "      <td>AP5Z1</td>\n",
       "      <td>HGNC:22197</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397704705</td>\n",
       "      <td>...</td>\n",
       "      <td>criteria provided, single submitter</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>ClinGen:CA215070,OMIM:613653.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4820844</td>\n",
       "      <td>GGAT</td>\n",
       "      <td>TGCTGTAAACTGTAACTGTAAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15041</td>\n",
       "      <td>Indel</td>\n",
       "      <td>NM_014855.3(AP5Z1):c.80_83delinsTGCTGTAAACTGTA...</td>\n",
       "      <td>9907</td>\n",
       "      <td>AP5Z1</td>\n",
       "      <td>HGNC:22197</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397704705</td>\n",
       "      <td>...</td>\n",
       "      <td>criteria provided, single submitter</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>ClinGen:CA215070,OMIM:613653.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4781213</td>\n",
       "      <td>GGAT</td>\n",
       "      <td>TGCTGTAAACTGTAACTGTAAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15042</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>NM_014855.3(AP5Z1):c.1413_1426del (p.Leu473fs)</td>\n",
       "      <td>9907</td>\n",
       "      <td>AP5Z1</td>\n",
       "      <td>HGNC:22197</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Jun 29, 2010</td>\n",
       "      <td>397704709</td>\n",
       "      <td>...</td>\n",
       "      <td>no assertion criteria provided</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>ClinGen:CA215072,OMIM:613653.0002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4827360</td>\n",
       "      <td>GCTGCTGGACCTGCC</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15042</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>NM_014855.3(AP5Z1):c.1413_1426del (p.Leu473fs)</td>\n",
       "      <td>9907</td>\n",
       "      <td>AP5Z1</td>\n",
       "      <td>HGNC:22197</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Jun 29, 2010</td>\n",
       "      <td>397704709</td>\n",
       "      <td>...</td>\n",
       "      <td>no assertion criteria provided</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>ClinGen:CA215072,OMIM:613653.0002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4787729</td>\n",
       "      <td>GCTGCTGGACCTGCC</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15043</td>\n",
       "      <td>single nucleotide variant</td>\n",
       "      <td>NM_014630.3(ZNF592):c.3136G&gt;A (p.Gly1046Arg)</td>\n",
       "      <td>9640</td>\n",
       "      <td>ZNF592</td>\n",
       "      <td>HGNC:28986</td>\n",
       "      <td>Uncertain significance</td>\n",
       "      <td>0</td>\n",
       "      <td>Jun 29, 2015</td>\n",
       "      <td>150829393</td>\n",
       "      <td>...</td>\n",
       "      <td>no assertion criteria provided</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>ClinGen:CA210674,UniProtKB:Q92610#VAR_064583,O...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>85342440</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780028</th>\n",
       "      <td>2831556</td>\n",
       "      <td>single nucleotide variant</td>\n",
       "      <td>NM_170707.4(LMNA):c.1685T&gt;C (p.Leu562Pro)</td>\n",
       "      <td>4000</td>\n",
       "      <td>LMNA</td>\n",
       "      <td>HGNC:6636</td>\n",
       "      <td>Uncertain significance</td>\n",
       "      <td>0</td>\n",
       "      <td>Oct 16, 2023</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>criteria provided, single submitter</td>\n",
       "      <td>1</td>\n",
       "      <td>ACMG2013,ACMG2016,ACMG2021,ACMG2022</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2664087</td>\n",
       "      <td>156107521</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780029</th>\n",
       "      <td>2831556</td>\n",
       "      <td>single nucleotide variant</td>\n",
       "      <td>NM_170707.4(LMNA):c.1685T&gt;C (p.Leu562Pro)</td>\n",
       "      <td>4000</td>\n",
       "      <td>LMNA</td>\n",
       "      <td>HGNC:6636</td>\n",
       "      <td>Uncertain significance</td>\n",
       "      <td>0</td>\n",
       "      <td>Oct 16, 2023</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>criteria provided, single submitter</td>\n",
       "      <td>1</td>\n",
       "      <td>ACMG2013,ACMG2016,ACMG2021,ACMG2022</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2664087</td>\n",
       "      <td>156137730</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780030</th>\n",
       "      <td>2831557</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>NC_000010.11:g.79055368_79303220del</td>\n",
       "      <td>57178</td>\n",
       "      <td>ZMIZ1</td>\n",
       "      <td>HGNC:16493</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>May 10, 2023</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>criteria provided, single submitter</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2664088</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780031</th>\n",
       "      <td>2831558</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>NM_003042.4(SLC6A1):c.336del (p.Gly112_Leu113i...</td>\n",
       "      <td>6529</td>\n",
       "      <td>SLC6A1</td>\n",
       "      <td>HGNC:11042</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Nov 27, 2023</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>criteria provided, single submitter</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2664089</td>\n",
       "      <td>11059620</td>\n",
       "      <td>CG</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780032</th>\n",
       "      <td>2831558</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>NM_003042.4(SLC6A1):c.336del (p.Gly112_Leu113i...</td>\n",
       "      <td>6529</td>\n",
       "      <td>SLC6A1</td>\n",
       "      <td>HGNC:11042</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Nov 27, 2023</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>criteria provided, single submitter</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2664089</td>\n",
       "      <td>11017934</td>\n",
       "      <td>CG</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4780033 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         #AlleleID                       Type  \\\n",
       "0            15041                      Indel   \n",
       "1            15041                      Indel   \n",
       "2            15042                   Deletion   \n",
       "3            15042                   Deletion   \n",
       "4            15043  single nucleotide variant   \n",
       "...            ...                        ...   \n",
       "4780028    2831556  single nucleotide variant   \n",
       "4780029    2831556  single nucleotide variant   \n",
       "4780030    2831557                   Deletion   \n",
       "4780031    2831558                   Deletion   \n",
       "4780032    2831558                   Deletion   \n",
       "\n",
       "                                                      Name  GeneID GeneSymbol  \\\n",
       "0        NM_014855.3(AP5Z1):c.80_83delinsTGCTGTAAACTGTA...    9907      AP5Z1   \n",
       "1        NM_014855.3(AP5Z1):c.80_83delinsTGCTGTAAACTGTA...    9907      AP5Z1   \n",
       "2           NM_014855.3(AP5Z1):c.1413_1426del (p.Leu473fs)    9907      AP5Z1   \n",
       "3           NM_014855.3(AP5Z1):c.1413_1426del (p.Leu473fs)    9907      AP5Z1   \n",
       "4             NM_014630.3(ZNF592):c.3136G>A (p.Gly1046Arg)    9640     ZNF592   \n",
       "...                                                    ...     ...        ...   \n",
       "4780028          NM_170707.4(LMNA):c.1685T>C (p.Leu562Pro)    4000       LMNA   \n",
       "4780029          NM_170707.4(LMNA):c.1685T>C (p.Leu562Pro)    4000       LMNA   \n",
       "4780030                NC_000010.11:g.79055368_79303220del   57178      ZMIZ1   \n",
       "4780031  NM_003042.4(SLC6A1):c.336del (p.Gly112_Leu113i...    6529     SLC6A1   \n",
       "4780032  NM_003042.4(SLC6A1):c.336del (p.Gly112_Leu113i...    6529     SLC6A1   \n",
       "\n",
       "            HGNC_ID    ClinicalSignificance  ClinSigSimple LastEvaluated  \\\n",
       "0        HGNC:22197              Pathogenic              1           NaN   \n",
       "1        HGNC:22197              Pathogenic              1           NaN   \n",
       "2        HGNC:22197              Pathogenic              1  Jun 29, 2010   \n",
       "3        HGNC:22197              Pathogenic              1  Jun 29, 2010   \n",
       "4        HGNC:28986  Uncertain significance              0  Jun 29, 2015   \n",
       "...             ...                     ...            ...           ...   \n",
       "4780028   HGNC:6636  Uncertain significance              0  Oct 16, 2023   \n",
       "4780029   HGNC:6636  Uncertain significance              0  Oct 16, 2023   \n",
       "4780030  HGNC:16493              Pathogenic              1  May 10, 2023   \n",
       "4780031  HGNC:11042              Pathogenic              1  Nov 27, 2023   \n",
       "4780032  HGNC:11042              Pathogenic              1  Nov 27, 2023   \n",
       "\n",
       "         RS# (dbSNP)  ...                         ReviewStatus  \\\n",
       "0          397704705  ...  criteria provided, single submitter   \n",
       "1          397704705  ...  criteria provided, single submitter   \n",
       "2          397704709  ...       no assertion criteria provided   \n",
       "3          397704709  ...       no assertion criteria provided   \n",
       "4          150829393  ...       no assertion criteria provided   \n",
       "...              ...  ...                                  ...   \n",
       "4780028           -1  ...  criteria provided, single submitter   \n",
       "4780029           -1  ...  criteria provided, single submitter   \n",
       "4780030           -1  ...  criteria provided, single submitter   \n",
       "4780031           -1  ...  criteria provided, single submitter   \n",
       "4780032           -1  ...  criteria provided, single submitter   \n",
       "\n",
       "        NumberSubmitters                           Guidelines TestedInGTR  \\\n",
       "0                      2                                  NaN           N   \n",
       "1                      2                                  NaN           N   \n",
       "2                      1                                  NaN           N   \n",
       "3                      1                                  NaN           N   \n",
       "4                      1                                  NaN           N   \n",
       "...                  ...                                  ...         ...   \n",
       "4780028                1  ACMG2013,ACMG2016,ACMG2021,ACMG2022           N   \n",
       "4780029                1  ACMG2013,ACMG2016,ACMG2021,ACMG2022           N   \n",
       "4780030                1                                  NaN           N   \n",
       "4780031                1                                  NaN           N   \n",
       "4780032                1                                  NaN           N   \n",
       "\n",
       "                                                  OtherIDs  \\\n",
       "0                        ClinGen:CA215070,OMIM:613653.0001   \n",
       "1                        ClinGen:CA215070,OMIM:613653.0001   \n",
       "2                        ClinGen:CA215072,OMIM:613653.0002   \n",
       "3                        ClinGen:CA215072,OMIM:613653.0002   \n",
       "4        ClinGen:CA210674,UniProtKB:Q92610#VAR_064583,O...   \n",
       "...                                                    ...   \n",
       "4780028                                                NaN   \n",
       "4780029                                                NaN   \n",
       "4780030                                                NaN   \n",
       "4780031                                                NaN   \n",
       "4780032                                                NaN   \n",
       "\n",
       "        SubmitterCategories VariationID PositionVCF ReferenceAlleleVCF  \\\n",
       "0                         3           2     4820844               GGAT   \n",
       "1                         3           2     4781213               GGAT   \n",
       "2                         1           3     4827360    GCTGCTGGACCTGCC   \n",
       "3                         1           3     4787729    GCTGCTGGACCTGCC   \n",
       "4                         1           4    85342440                  G   \n",
       "...                     ...         ...         ...                ...   \n",
       "4780028                   2     2664087   156107521                  T   \n",
       "4780029                   2     2664087   156137730                  T   \n",
       "4780030                   2     2664088          -1                NaN   \n",
       "4780031                   2     2664089    11059620                 CG   \n",
       "4780032                   2     2664089    11017934                 CG   \n",
       "\n",
       "             AlternateAlleleVCF  \n",
       "0        TGCTGTAAACTGTAACTGTAAA  \n",
       "1        TGCTGTAAACTGTAACTGTAAA  \n",
       "2                             G  \n",
       "3                             G  \n",
       "4                             A  \n",
       "...                         ...  \n",
       "4780028                       C  \n",
       "4780029                       C  \n",
       "4780030                     NaN  \n",
       "4780031                       C  \n",
       "4780032                       C  \n",
       "\n",
       "[4780033 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8563e-490b-49f1-a64e-04db5295982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar = pd.read_csv('ClinVar_variants.txt', sep='\\t', na_values=['-','na'], low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "92302b00-fede-4089-97fd-c81995701196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from 4780033\n",
      "to 2356445 after filtering for the assembly\n",
      "to 2141442 after filtering for SNVs\n",
      "to 1704850 after filtering for mutations with the p. HGVS expression\n",
      "to 1469843 after filtering for mutations in the canonical isoforms\n",
      "to 1468891 after comparing with the length of the sequence of the canonical isoform\n",
      "to 1466286 after restricting to mutations whose WT amino acid matches the one we find in the same position of the canonical isoform\n",
      "to 1070494 after taking non-synonymous mutations only\n",
      "to 1047477 after taking germline mutations\n",
      "to 1044160 after taking mutations with the interpretable clinical significance\n"
     ]
    }
   ],
   "source": [
    "eng = sqlalchemy.create_engine('mysql://', creator= db_utils.get_connection)\n",
    "\n",
    "# import the new clinvar dataset:\n",
    "clinvar = pd.read_csv('ClinVar_variants.txt', sep='\\t', na_values=['-','na'], low_memory=False)\n",
    "clinvar.rename(columns={clinvar.columns[0]:'AlleleID'}, inplace=True)\n",
    "clinvar.insert(2,'RefSeq_ID', clinvar['Name'].str.split('.').str[0], True)\n",
    "\n",
    "# reduce the dataset to GRCh38 assembly:\n",
    "print('from', clinvar.shape[0])\n",
    "clinvar = clinvar[clinvar['Assembly'] == 'GRCh38']\n",
    "print('to', clinvar.shape[0], 'after filtering for the assembly')\n",
    "\n",
    "# filter for single nucleotide variants\n",
    "clinvar = clinvar[clinvar['Type'].str.contains('single nucleotide variant')]\n",
    "print('to', clinvar.shape[0], 'after filtering for SNVs')\n",
    "\n",
    "# and variants having the protein amino acid change in their notation\n",
    "clinvar = clinvar[clinvar['Name'].str.contains('p.')]\n",
    "print('to', clinvar.shape[0], 'after filtering for mutations with the p. HGVS expression')\n",
    "\n",
    "### filter for the mutations falling into the canonical isoform:\n",
    "# to map RefSeq IDs to isoform IDs, I used biomart: filtered for chromosomes, and selected the following identifiers:\n",
    "# RefSeq mRNA ID\n",
    "# UniProtKB isoform ID\n",
    "# UniProtKB/Swiss-Prot ID\n",
    "mapping = pd.read_csv('RefSeq_to_iso.txt', sep='\\t')\n",
    "mapping.rename(columns={'RefSeq mRNA ID':'RefSeq_ID','UniProtKB isoform ID':'Ref_Seq_to_iso', 'UniProtKB/Swiss-Prot ID':'uni_AC'}, inplace=True)\n",
    "mapping.drop_duplicates(inplace=True)\n",
    "mapping = mapping[~(mapping['RefSeq_ID'].isna()) & ~(mapping['uni_AC'].isna())]\n",
    "mapping.loc[mapping['Ref_Seq_to_iso'].isna(), 'Ref_Seq_to_iso'] = mapping.loc[mapping['Ref_Seq_to_iso'].isna(), 'uni_AC']\n",
    "\n",
    "# load a list of canonical isoforms:\n",
    "can_iso = pd.read_csv(find_file('Canonical_isoforms.csv'), header=0, sep=',')\n",
    "mapping = mapping.merge(can_iso, how='inner', left_on='uni_AC', right_on='uniprot_id')\n",
    "mapping = mapping[['RefSeq_ID','uni_AC','Ref_Seq_to_iso','uniprot_iso_id']]\n",
    "mapping = mapping[mapping['Ref_Seq_to_iso'] == mapping['uniprot_iso_id']][['RefSeq_ID','uni_AC','Ref_Seq_to_iso']] # only keep refseq IDs which map to canonical isoforms\n",
    "mapping.drop_duplicates(inplace=True)\n",
    "\n",
    "# restrict to mutations which map to canonical isoforms:\n",
    "clinvar = clinvar.merge(mapping, how='inner', on='RefSeq_ID')\n",
    "print('to', clinvar.shape[0], 'after filtering for mutations in the canonical isoforms')\n",
    "\n",
    "# WT amino acids at the mutated site needs to match the sequence of the canonical isoform:\n",
    "\n",
    "# extract amino acid change information:\n",
    "clinvar.reset_index(inplace = True, drop = True)\n",
    "# extract amino acid change\n",
    "clinvar.insert(4, 'aa_change', clinvar['Name'].str.extract(r'p\\.(.*?)\\)')[0].tolist(), True)\n",
    "# make extra column for position of aa change\n",
    "clinvar.insert(5,'aa_pos', clinvar['aa_change'].str.extract(r'(\\d{1,})', expand=False), True)\n",
    "# make extra column to get WT amino acid -> I later checked that all the WT_aa entries consist of 3 letters.\n",
    "clinvar.insert(6, 'WT_aa', clinvar['aa_change'].str.extract(r'(^[a-zA-Z]{0,3})', expand=False),True)\n",
    "# convert aa into single letter\n",
    "clinvar.replace({'WT_aa': protein_letters_3to1}, inplace =True)\n",
    "# make extra column for alternate amino acid\n",
    "# a = in the alternate amino acid column indicates that the variant has no predicted effect on the protein level\n",
    "clinvar.insert(7, 'alt_aa', clinvar['aa_change'].str.extract(r'(\\D{0,3}$)', expand=False),True)\n",
    "# convert aa into single letter\n",
    "clinvar.replace({'alt_aa': protein_letters_3to1}, inplace =True)\n",
    "\n",
    "# merge with the sequences of uniprot isoforms\n",
    "clinvar = clinvar.merge(can_iso, how='inner', left_on='Ref_Seq_to_iso', right_on='uniprot_iso_id')\n",
    "# the mutation position needs to be lower than the length:\n",
    "clinvar['len_ok'] = pd.Series([(int(clinvar.loc[row,'aa_pos']) <= len(clinvar.loc[row,'sequence'])) for row in clinvar.index])\n",
    "clinvar = clinvar[clinvar['len_ok']]\n",
    "clinvar.reset_index(inplace=True, drop=True)\n",
    "print('to', clinvar.shape[0], 'after comparing with the length of the sequence of the canonical isoform')\n",
    "\n",
    "# the WT amino acid needs to match the one we find in the same position of the canonical isoform:\n",
    "clinvar['WT_aa_in_iso'] = [a[int(b)-1] for a, b in zip(clinvar['sequence'], clinvar['aa_pos'])]\n",
    "clinvar = clinvar[(clinvar['WT_aa'] == clinvar['WT_aa_in_iso'])]\n",
    "print('to', clinvar.shape[0], 'after restricting to mutations whose WT amino acid matches the one we find in the same position of the canonical isoform')\n",
    "\n",
    "# let's select non-synonymous variants only:\n",
    "clinvar = clinvar[(clinvar['alt_aa'] != '=')]\n",
    "print('to', clinvar.shape[0], 'after taking non-synonymous mutations only')\n",
    "\n",
    "# filter for germline mutations:\n",
    "clinvar = clinvar[clinvar['OriginSimple']=='germline']\n",
    "print('to', clinvar.shape[0], 'after taking germline mutations')\n",
    "\n",
    "# filter for definite clinical significance:\n",
    "clinvar = clinvar[clinvar['ClinicalSignificance'].isin(['Uncertain significance', 'Likely benign', 'Benign', 'Pathogenic', 'Likely pathogenic', 'Benign/Likely benign', 'Pathogenic/Likely pathogenic','Conflicting interpretations of pathogenicity'])]\n",
    "print('to', clinvar.shape[0], 'after taking mutations with the interpretable clinical significance')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0bf01367-d55e-4638-bfd0-5401abc00c68",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['AlleleID', 'VariationID', 'Chromosome', 'Start', 'ReferenceAlleleVCF', 'AlternateAlleleVCF', 'GeneSymbol', 'uni_AC', 'ClinicalSignificance', 'PhenotypeList'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-32ca846eef46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclinvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclinvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AlleleID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VariationID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Chromosome'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Start'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ReferenceAlleleVCF'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AlternateAlleleVCF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GeneSymbol'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'uni_AC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'uniprot_iso_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aa_change'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'ClinicalSignificance'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'PhenotypeList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclinvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'AlleleID'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'allele_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VariationID'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'variation_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Chromosome'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'chromosome'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Start'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'coords'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ReferenceAlleleVCF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'ref'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AlternateAlleleVCF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'alt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'GeneSymbol'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'gene_symbol'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'uni_AC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'uniprot_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Uniprot_iso'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'uniprot_iso_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ClinicalSignificance'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'pathogenicity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PhenotypeList'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'phenotype'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# introduce the composite_id column:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclinvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'composite_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclinvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chromosome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclinvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclinvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ref'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclinvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3813\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3815\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6068\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6070\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6072\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6132\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6133\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6135\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['AlleleID', 'VariationID', 'Chromosome', 'Start', 'ReferenceAlleleVCF', 'AlternateAlleleVCF', 'GeneSymbol', 'uni_AC', 'ClinicalSignificance', 'PhenotypeList'] not in index\""
     ]
    }
   ],
   "source": [
    "clinvar = clinvar[['AlleleID', 'VariationID', 'Chromosome', 'Start', 'ReferenceAlleleVCF','AlternateAlleleVCF', 'GeneSymbol','uni_AC', 'uniprot_iso_id', 'aa_change',  'ClinicalSignificance',  'PhenotypeList']]\n",
    "clinvar.rename(columns={'AlleleID': 'allele_id', 'VariationID':'variation_id','Chromosome':'chromosome', 'Start':'coords','ReferenceAlleleVCF':'ref','AlternateAlleleVCF':'alt','GeneSymbol':'gene_symbol','uni_AC':'uniprot_id','Uniprot_iso':'uniprot_iso_id', 'ClinicalSignificance':'pathogenicity','PhenotypeList':'phenotype'}, inplace=True)\n",
    "\n",
    "# introduce the composite_id column:\n",
    "clinvar['composite_id'] = ['_'.join([str(i) for i in [a, b, c, d]]) for a, b, c, d in zip(clinvar['chromosome'], clinvar['coords'], clinvar['ref'], clinvar['alt'])]\n",
    "\n",
    "# clean up pathogenicity and phenotype columns:\n",
    "dictionary = {'Uncertain significance':'uncertain', 'Pathogenic':'pathogenic', 'Conflicting interpretations of pathogenicity':'conflicting', 'Likely pathogenic':'pathogenic', 'Benign':'benign', 'Likely benign':'benign', 'Pathogenic/Likely pathogenic':'pathogenic', 'Benign/Likely benign':'benign'}\n",
    "for k, v in dictionary.items():\n",
    "    clinvar['pathogenicity'] = clinvar['pathogenicity'].str.replace(k, v)\n",
    "dictionary = {'pathogenic/pathogenic':'pathogenic', 'benign/benign':'benign'}\n",
    "for k, v in dictionary.items():\n",
    "    clinvar['pathogenicity'] = clinvar['pathogenicity'].str.replace(k, v)\n",
    "clinvar['phenotype']  =[i.lower().replace('|', ' | ').replace('-', '').replace(' | not provided', '').replace(' | not specified', '').replace('not provided | ', '').replace('not specified | ', '').replace('not provided, ', '').replace(', not provided', '') for i in clinvar['phenotype']]\n",
    "clinvar['phenotype'] = clinvar['phenotype'].replace({'not provided':None}) #change to proper None values\n",
    "clinvar['phenotype'] = clinvar['phenotype'].replace({'not specified':None}) #change to proper None values\n",
    "# filter out Ter mutations: \n",
    "clinvar = clinvar[~(clinvar['aa_change'].str.contains('Ter'))]\n",
    "# reorder the columns:\n",
    "clinvar = clinvar[clinvar.columns.tolist()[:6] + ['composite_id'] + clinvar.columns.tolist()[6:-1]]\n",
    "clinvar.drop_duplicates(inplace=True)\n",
    "clinvar.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Now, we did compare reference amino acid to swissprot sequences but we did not compare to John's version, so I will do that:\n",
    "\n",
    "#I need to prepare clinvar_m dataset first by introducing some columns\n",
    "clinvar_m = clinvar.copy(deep=True)\n",
    "clinvar_m.reset_index(inplace=True, drop=True)\n",
    "clinvar_m['aa_ref'] = [i[:3] for i in clinvar_m['aa_change']]\n",
    "clinvar_m['aa_alt'] = [i[-3:] for i in clinvar_m['aa_change']]\n",
    "clinvar_m['aa_pos'] = [int(''.join([a for a in i if a.isdigit()])) for i in clinvar_m['aa_change']]\n",
    "clinvar_m['aa_ref_short'] = clinvar_m['aa_ref'] \n",
    "clinvar_m['aa_alt_short'] = clinvar_m['aa_alt']\n",
    "AA_dict = {'Phe':'F','Leu':'L','Ser':'S','Tyr':'Y','Cys':'C','Trp':'W','Pro':'P','His':'H','Gln':'Q','Arg':'R','Ile':'I','Met':'M','Thr':'T','Asn':'N','Lys':'K','Val':'V','Ala':'A','Asp':'D','Glu':'E','Gly':'G','Ter':'*'}\n",
    "clinvar_m['aa_ref_short'] = [AA_dict.get(i) for i in clinvar_m['aa_ref_short']]\n",
    "clinvar_m['aa_alt_short'] = [AA_dict.get(i) for i in clinvar_m['aa_alt_short']]\n",
    "\n",
    "# loading John's dataset\n",
    "query = '''select * from chopyan_db.uniprot_id_sequence as df'''\n",
    "john_seq = pd.read_sql_query(query, con=eng)\n",
    "\n",
    "compare_ref_aa = clinvar_m.merge(john_seq, how='inner', on='uniprot_id')\n",
    "compare_ref_aa['length'] = [len(i) for i in compare_ref_aa['sequence'].values]\n",
    "\n",
    "print(len(compare_ref_aa[compare_ref_aa['aa_pos'] > compare_ref_aa['length']]))\n",
    "compare_ref_aa = compare_ref_aa[compare_ref_aa['aa_pos'] <= compare_ref_aa['length']]\n",
    "\n",
    "#compare the actual sequences:\n",
    "compare_ref_aa['swiss_prot_ref_aa'] = [seq[pos-1] for seq, pos in zip(compare_ref_aa['sequence'].values, compare_ref_aa['aa_pos'].values)]\n",
    "print(len(compare_ref_aa[compare_ref_aa['aa_ref_short'] != compare_ref_aa['swiss_prot_ref_aa']]))\n",
    "compare_ref_aa = compare_ref_aa[compare_ref_aa['aa_ref_short'] == compare_ref_aa['swiss_prot_ref_aa']]\n",
    "\n",
    "clinvar = compare_ref_aa.copy(deep=True)\n",
    "clinvar.drop(columns=['sequence','length','swiss_prot_ref_aa'], inplace=True)\n",
    "clinvar.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f905da6a-cf80-40ed-b359-ecaf4400ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_m = clinvar.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b379d158-1c53-4a90-8d91-295a21976311",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n",
      "a 10 000 done\n"
     ]
    }
   ],
   "source": [
    "# I think I also want to run NDD annotation on this again, because I did it a bit differently from Kristina:\n",
    "\n",
    "### I already made it lowercase, removed -, changed | into | with spaces around it. I also checked NaN values and there are None in this column:\n",
    "\n",
    "#preparing human phenotype ontology (HPO) list of NDD phenotypes and keyword search data\n",
    "#load HPO\n",
    "hpo_ndds = pd.read_excel(find_file('HPO_NDDs.xlsx'), header=0)\n",
    "\n",
    "#lower string, replace '-', and '|', and create a single string:\n",
    "hpo_ndds['DISEASE_NAME'] = [i.lower() for i in hpo_ndds['DISEASE_NAME']]\n",
    "hpo_ndds['DISEASE_NAME'] = hpo_ndds['DISEASE_NAME'].str.replace('-', ' ')\n",
    "hpo_string_data = ' | '.join([i for i in hpo_ndds['DISEASE_NAME']])\n",
    "filpat = r',? ?(Autosomal|Somatic) ?(Dominant|Recessive)? ?\\d*|,? ?((Type)? \\d\\w?|Type \\w{2}) ?'\n",
    "hpo = pd.DataFrame(hpo_string_data.split(' | '))\n",
    "hpo.rename(columns={0:'phenotype'}, inplace=True)\n",
    "hpo.phenotype = hpo.phenotype.str.replace(filpat, '', flags = re.IGNORECASE, regex = True)\n",
    "hpo_string_data = ' | '.join([i for i in hpo['phenotype']])\n",
    "\n",
    "#prepare keyword search string:\n",
    "keyword_search = ' | '.join(['neurodevelopment', 'learning disability', 'cognitive impairment', 'mental retardation', 'intellectual disability', 'autism', 'autistic', 'epilepsy', 'epileptic', 'developmental delay', 'delayed development'])\n",
    "#learning disability is a synonym of intellectual disability, but for example learning difficulties can be referring to something else, like dyslexia\n",
    "#cognitive impairment is also a synonym of intellectual disability\n",
    "#I put neurodevelopment instead of neuro because neuro will also include neuropathies and so on\n",
    "\n",
    "clinvar_m['hpo'] = clinvar_m['phenotype'] #had to do this because the ndd_annotation function is written for hpo and phenotype columns\n",
    "\n",
    "def ndd_annotation(dataset, comparison_string, string_name):\n",
    "    '''\n",
    "    Annotate phenotypes as NDD associated or not, based on a list of NDD phenotypes\n",
    "    dataset -> df; the dataset which contains 'phenotype' column which lists phenotypes associated with each variant, and 'hpo' column which lists hpo identifiers for those phenotypes\n",
    "    comparison_string -> str; string which contains a list of NDD phenotypes separated with a |; I used either a list of NDD phenotypes provided by the HPO ontology or the keyword search list I built myself\n",
    "    string_name -> str; name of the comparison_string, so that I can change the values in the corresponding columns\n",
    "    \n",
    "    Returns a dataframe with 3 additional columns: one which lists phenotypes which were found to be NDD-associated, second which lists their corresponding HPO identifiers and the last one which says True\n",
    "    if at least one of the phenotypes in at least one of the patients were found to be NDD-associated. Also, I did the string matching both ways - if the phenotype in the phenotype column is in the\n",
    "    string and also if elements of the string are matching to one of the phenotypes in the phenotype column. Either way, the phenotypes which were found to be a match are listed in the f'phenotype_ndd_in_{string_name}'\n",
    "    column and those are the phenotypes that are in the phenotype column (they are not taken from the string).\n",
    "    '''\n",
    "    \n",
    "    dataset[f'phenotype_ndd_in_{string_name}'] = False\n",
    "    dataset[f'hpo_ndd_in_{string_name}'] = False\n",
    "    dataset[f'ndd_in_{string_name}'] = False\n",
    "    \n",
    "    dataset[f'phenotype_ndd_in_{string_name}'] = dataset[f'phenotype_ndd_in_{string_name}'].astype(dtype='object') \n",
    "    dataset[f'hpo_ndd_in_{string_name}'] = dataset[f'phenotype_ndd_in_{string_name}'].astype(dtype='object')\n",
    "    dataset[f'ndd_in_{string_name}'] = dataset[f'phenotype_ndd_in_{string_name}'].astype(dtype='object')\n",
    "    \n",
    "    for n, (phe, hpo) in enumerate(zip(dataset['phenotype'].values, dataset['hpo'].values)):\n",
    "        if n % 10000 == 0:\n",
    "            print('a 10 000 done')\n",
    "        if type(phe) != type(hpo): #I expect them to be same type and if this is not the case, I want to be alarmed\n",
    "            print('alarm')\n",
    "        if dataset.loc[n, 'phenotype'] == None:\n",
    "            dataset.at[n, f'phenotype_ndd_in_{string_name}'] = None\n",
    "            dataset.at[n, f'hpo_ndd_in_{string_name}'] = None #and the third column will say false!\n",
    "        comparison_list = list(set(comparison_string.split(' | '))) # hpo string may have some duplicates because it's basically a tree!\n",
    "        if type(dataset.at[n, 'phenotype']) == str:\n",
    "            phe_list = phe.split(' | ') #this is now a list of phenotypes\n",
    "            hpo_list = hpo.split(' | ') #I defined it here because I will use it in the first and the second if statement\n",
    "            if True in [True for i in phe_list if i in comparison_string]:\n",
    "                dataset.at[n, f'ndd_in_{string_name}'] = True\n",
    "                dataset.at[n, f'phenotype_ndd_in_{string_name}'] = ' | '.join([i for i in phe_list if i in comparison_string]) #if any of them are in the list\n",
    "                get_indices = [phe_list.index(i) for i in phe_list if i in comparison_string]\n",
    "                dataset.at[n, f'hpo_ndd_in_{string_name}'] = ' | '.join(list(np.array(hpo_list)[get_indices])) #get those exact HPO IDs also !\n",
    "            ######################\n",
    "            #now I want to check the other way around\n",
    "            if True in [True for i in comparison_list if i in phe]:\n",
    "                dataset.at[n, f'ndd_in_{string_name}'] = True #again, immediately set to True, so if it's either the previous thing or this thing, I want it to be set to true\n",
    "                if True not in [True for i in phe_list if i in comparison_string]: #if the previous statement is not true, then there is no need to concatenate the 2 strings\n",
    "                    #first let's get a list of matches from the comparison_list\n",
    "                    list_of_matches = [i for i in comparison_list if i in phe]\n",
    "                    #now let's get phenotypes which contain these matches!\n",
    "                    dataset.at[n, f'phenotype_ndd_in_{string_name}'] = ' | '.join(list(OrderedDict.fromkeys([i for i in phe_list for x in list_of_matches if x in i]))) #if one of the elements contains both of the matches, it will be mentioned twice and there is no need for that; for example 'autistic behavior, intellectual disability | skeletal disorder', the first element will appear twice, but this is unlikely #used set\n",
    "                    get_indices = list(OrderedDict.fromkeys([phe_list.index(i) for i in phe_list for x in list_of_matches if x in i])) #the reason I used ordereddict is because it preserves order!\n",
    "                    dataset.at[n, f'hpo_ndd_in_{string_name}'] = ' | '.join(list(OrderedDict.fromkeys(list(np.array(hpo_list)[get_indices])))) #get those exact HPO IDs also ! #used set\n",
    "                if True in [True for i in phe_list if i in comparison_string]: #if this is a True statement, then I want to concatenate this and the previous value\n",
    "                    phe_value_1 = ' | '.join([i for i in phe_list if i in comparison_string])\n",
    "                    get_indices = [phe_list.index(i) for i in phe_list if i in comparison_string]\n",
    "                    hpo_value_1 = ' | '.join(list(np.array(hpo_list)[get_indices]))\n",
    "                    #value 2:\n",
    "                    list_of_matches = [i for i in comparison_list if i in phe]\n",
    "                    phe_value_2 = ' | '.join(list(OrderedDict.fromkeys([i for i in phe_list for x in list_of_matches if x in i])))\n",
    "                    get_indices = list(OrderedDict.fromkeys([phe_list.index(i) for i in phe_list for x in list_of_matches if x in i]))\n",
    "                    hpo_value_2 = ' | '.join(list(OrderedDict.fromkeys(list(np.array(hpo_list)[get_indices]))))\n",
    "                    #final value:\n",
    "                    phe_value = phe_value_1 + ' | ' + phe_value_2\n",
    "                    phe_value = ' | '.join(list(OrderedDict.fromkeys(phe_value.split(' | ')))) #I wanna take a set in that case #I'm afraid this might change the order but let's see, as long as we do the same thing with hpo, should be fine?\n",
    "                    hpo_value = hpo_value_1 + ' | ' + hpo_value_2\n",
    "                    hpo_value = ' | '.join(list(OrderedDict.fromkeys(hpo_value.split(' | '))))\n",
    "                    dataset.at[n, f'phenotype_ndd_in_{string_name}'] = phe_value\n",
    "                    dataset.at[n, f'hpo_ndd_in_{string_name}'] = hpo_value\n",
    "            if (True not in [True for i in phe_list if i in comparison_string]) & (True not in [True for i in comparison_list if i in phe]):\n",
    "                dataset.at[n, f'phenotype_ndd_in_{string_name}'] = None #if we cannot find matches either way, then we set this to None and the columns will stay 'False'\n",
    "                dataset.at[n, f'hpo_ndd_in_{string_name}'] = None\n",
    "        if type(dataset.at[n, 'phenotype']) == list: #this would be a list of strings\n",
    "            new_value_phe = []\n",
    "            new_value_hpo = []\n",
    "            for phe_string, hpo_string in zip(phe, hpo): #we go through one string first\n",
    "                if phe_string == None: #if one of the values is None, which means that the phenotype for one patient is not available and then hpo will also be None\n",
    "                    pass\n",
    "                else: #this is now if it's a string basically\n",
    "                    phe_list = phe_string.split(' | ') #I gotta define this now for every string of the list, if type(dataset.at[n, 'phenotype']) == list\n",
    "                    hpo_list = hpo_string.split(' | ')\n",
    "                    if True in [True for i in phe_list if i in comparison_string]:\n",
    "                        dataset.at[n, f'ndd_in_{string_name}'] = True\n",
    "                        new_value_phe = new_value_phe + [i for i in phe_list if i in comparison_string] #I don't want to append a list, then it will be a list of lists\n",
    "                        get_indices = [phe_list.index(i) for i in phe_list if i in comparison_string]\n",
    "                        new_value_hpo = new_value_hpo + list(np.array(hpo_list)[get_indices])\n",
    "                    ######################\n",
    "                    #now I want to check the other way around\n",
    "                    #I already defined the comparison list up there\n",
    "                    if True in [True for i in comparison_list if i in phe_string]:\n",
    "                        dataset.at[n, f'ndd_in_{string_name}'] = True #again, immediately set to True, so if it's either the previous thing or this thing, I want it to be set to true\n",
    "                        #first let's get a list of matches from the comparison_list\n",
    "                        list_of_matches = [i for i in comparison_list if i in phe_string]\n",
    "                        #now let's get phenotypes which contain these matches!\n",
    "                        new_value_phe = new_value_phe + list(OrderedDict.fromkeys([i for i in phe_list for x in list_of_matches if x in i]))\n",
    "                        get_indices = list(OrderedDict.fromkeys([phe_list.index(i) for i in phe_list for x in list_of_matches if x in i]))\n",
    "                        new_value_hpo = new_value_hpo + list(OrderedDict.fromkeys(list(np.array(hpo_list)[get_indices])))\n",
    "                    if (True not in [True for i in phe_list if i in comparison_string]) & (True not in [True for i in comparison_list if i in phe_string]):\n",
    "                        pass\n",
    "            if new_value_phe == []: #if there are no None values and also if none of the phenotypes match\n",
    "                new_value_phe = None\n",
    "                new_value_hpo = None\n",
    "            else:\n",
    "                new_value_phe = ' | '.join(list(OrderedDict.fromkeys(new_value_phe))) #so far I was just concatenating strings to the new_value_hpo, but now i WANT\n",
    "                new_value_hpo = ' | '.join(list(OrderedDict.fromkeys(new_value_hpo)))\n",
    "            dataset.at[n, f'phenotype_ndd_in_{string_name}'] = new_value_phe\n",
    "            dataset.at[n, f'hpo_ndd_in_{string_name}'] = new_value_hpo\n",
    "    return dataset\n",
    "\n",
    "clinvar_m = ndd_annotation(clinvar_m, hpo_string_data, 'hpo')\n",
    "clinvar_m = ndd_annotation(clinvar_m, keyword_search, 'keyword_search')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5f6efea9-0236-46cf-bf71-6494297035f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clinvar_m['ndd_phe'] = [1 if (a or b) == True else 0 for a,b in zip(clinvar_m['ndd_in_hpo'], clinvar_m['ndd_in_keyword_search'])]\n",
    "\n",
    "# keep the columns I think are worth saving in a file:\n",
    "# clinvar_m = clinvar_m[clinvar_m.columns.tolist()[:10] + ['aa_change', 'aa_ref','aa_alt', 'aa_pos', 'aa_ref_short', 'aa_alt_short', 'pathogenicity', 'phenotype', 'phenotype_ndd_in_hpo','ndd_in_hpo','phenotype_ndd_in_keyword_search','ndd_in_keyword_search','ndd_phe_m']]\n",
    "# clinvar_m.to_csv('output/clinvar_filtered_kristina_milena.csv', header=True, sep='\\t', index=False)\n",
    "# clinvar_m = pd.read_csv(find_file('clinvar_filtered_kristina_milena.csv'), sep='\\t', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9030fe3c-433c-4b37-8667-62a92cb241f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clinvar = clinvar_m.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "b78b7363-31a3-42da-8c5d-67a3bc76d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clinvar = new_clinvar[new_clinvar.columns.tolist()[:10] + ['aa_change', 'aa_ref','aa_alt', 'aa_pos', 'aa_ref_short', 'aa_alt_short', 'pathogenicity', 'phenotype', 'phenotype_ndd_in_hpo','ndd_in_hpo','phenotype_ndd_in_keyword_search','ndd_in_keyword_search','ndd_phe']]\n",
    "%store new_clinvar\n",
    "new_clinvar.to_csv('output/clinvar_filtered_milena_2023.csv', header=True, sep='\\t', index=False)\n",
    "new_clinvar = pd.read_csv(find_file('clinvar_filtered_milena_2023.csv'), sep='\\t', header=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
