{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b30496-1e1c-4f99-942a-07803006b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from find_path import find_file\n",
    "from operator import itemgetter\n",
    "from collections import OrderedDict\n",
    "from matplotlib_venn import venn2\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sqlalchemy\n",
    "import db_utils\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e7b77e-fd94-42b5-bece-8b49591939aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load DDD mutations\n",
    "eng = sqlalchemy.create_engine('mysql://', creator= db_utils.get_connection)\n",
    "# query = '''select * from milena_db.DDD_mutations_mapped_filtered as df'''\n",
    "# ddd = pd.read_sql_query(query, con=eng)\n",
    "# ddd['chromosome'] = [int(i) if str(i).isdigit() else str(i) for i in ddd['chromosome']]\n",
    "\n",
    "# I added one extra column to the DDD study dataset ('pathogenicity_conflict'), which I need here to add it to the merged dataset, but I didn't push this to mysql, so I will alternatively load it here:\n",
    "# comes from ddd_study notebook\n",
    "%store -r mapped_grouped\n",
    "ddd = mapped_grouped.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac34e275-7b0a-40a4-9db3-b4ea063cec59",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allele_id</th>\n",
       "      <th>variation_id</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>coords</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>composite_id</th>\n",
       "      <th>gene_symbol</th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>uniprot_iso_id</th>\n",
       "      <th>aa_change</th>\n",
       "      <th>pathogenicity</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>ndd_phe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15043</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>84799209</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>15_84799209_G_A</td>\n",
       "      <td>ZNF592</td>\n",
       "      <td>Q92610</td>\n",
       "      <td>Q92610</td>\n",
       "      <td>Gly1046Arg</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>galloway mowat syndrome 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15045</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>126277517</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>11_126277517_A_G</td>\n",
       "      <td>FOXRED1</td>\n",
       "      <td>Q96CU9</td>\n",
       "      <td>Q96CU9-1</td>\n",
       "      <td>Asn430Ser</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>mitochondrial complex 1 deficiency, nuclear ty...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15046</td>\n",
       "      <td>214885</td>\n",
       "      <td>14</td>\n",
       "      <td>31562125</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>14_31562125_G_A</td>\n",
       "      <td>NUBPL</td>\n",
       "      <td>Q8TB37</td>\n",
       "      <td>Q8TB37-1</td>\n",
       "      <td>Gly56Arg</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>inborn genetic diseases | mitochondrial comple...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15050</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>26090957</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>6_26090957_A_T</td>\n",
       "      <td>HFE</td>\n",
       "      <td>Q30201</td>\n",
       "      <td>Q30201-1</td>\n",
       "      <td>Ser65Cys</td>\n",
       "      <td>conflicting</td>\n",
       "      <td>hemochromatosis type 1 | hereditary hemochroma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15051</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>26091078</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>6_26091078_T_C</td>\n",
       "      <td>HFE</td>\n",
       "      <td>Q30201</td>\n",
       "      <td>Q30201-1</td>\n",
       "      <td>Ile105Thr</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>hemochromatosis type 1 | hereditary hemochroma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329555</th>\n",
       "      <td>1330396</td>\n",
       "      <td>1339345</td>\n",
       "      <td>22</td>\n",
       "      <td>20988856</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>22_20988856_T_C</td>\n",
       "      <td>LZTR1</td>\n",
       "      <td>Q8N653</td>\n",
       "      <td>Q8N653</td>\n",
       "      <td>Tyr193His</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>inborn genetic diseases</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329556</th>\n",
       "      <td>1330410</td>\n",
       "      <td>1339351</td>\n",
       "      <td>19</td>\n",
       "      <td>1469921</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>19_1469921_C_T</td>\n",
       "      <td>APC2</td>\n",
       "      <td>O95996</td>\n",
       "      <td>O95996-1</td>\n",
       "      <td>Pro2207Leu</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>sotos syndrome 3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329557</th>\n",
       "      <td>1330411</td>\n",
       "      <td>1339352</td>\n",
       "      <td>19</td>\n",
       "      <td>1457099</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>19_1457099_G_A</td>\n",
       "      <td>APC2</td>\n",
       "      <td>O95996</td>\n",
       "      <td>O95996-1</td>\n",
       "      <td>Val355Ile</td>\n",
       "      <td>pathogenic</td>\n",
       "      <td>sotos syndrome 3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329558</th>\n",
       "      <td>1330414</td>\n",
       "      <td>1339355</td>\n",
       "      <td>1</td>\n",
       "      <td>16992363</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>1_16992363_G_A</td>\n",
       "      <td>ATP13A2</td>\n",
       "      <td>Q9NQ11</td>\n",
       "      <td>Q9NQ11-1</td>\n",
       "      <td>Pro629Ser</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>spastic tetraparesis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329559</th>\n",
       "      <td>1330415</td>\n",
       "      <td>1339356</td>\n",
       "      <td>16</td>\n",
       "      <td>89553052</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>16_89553052_C_G</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>Q9UQ90</td>\n",
       "      <td>Q9UQ90-1</td>\n",
       "      <td>Thr618Ser</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>spastic tetraparesis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329560 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        allele_id  variation_id chromosome     coords ref alt  \\\n",
       "0           15043             4         15   84799209   G   A   \n",
       "1           15045             6         11  126277517   A   G   \n",
       "2           15046        214885         14   31562125   G   A   \n",
       "3           15050            11          6   26090957   A   T   \n",
       "4           15051            12          6   26091078   T   C   \n",
       "...           ...           ...        ...        ...  ..  ..   \n",
       "329555    1330396       1339345         22   20988856   T   C   \n",
       "329556    1330410       1339351         19    1469921   C   T   \n",
       "329557    1330411       1339352         19    1457099   G   A   \n",
       "329558    1330414       1339355          1   16992363   G   A   \n",
       "329559    1330415       1339356         16   89553052   C   G   \n",
       "\n",
       "            composite_id gene_symbol uniprot_id uniprot_iso_id   aa_change  \\\n",
       "0        15_84799209_G_A      ZNF592     Q92610         Q92610  Gly1046Arg   \n",
       "1       11_126277517_A_G     FOXRED1     Q96CU9       Q96CU9-1   Asn430Ser   \n",
       "2        14_31562125_G_A       NUBPL     Q8TB37       Q8TB37-1    Gly56Arg   \n",
       "3         6_26090957_A_T         HFE     Q30201       Q30201-1    Ser65Cys   \n",
       "4         6_26091078_T_C         HFE     Q30201       Q30201-1   Ile105Thr   \n",
       "...                  ...         ...        ...            ...         ...   \n",
       "329555   22_20988856_T_C       LZTR1     Q8N653         Q8N653   Tyr193His   \n",
       "329556    19_1469921_C_T        APC2     O95996       O95996-1  Pro2207Leu   \n",
       "329557    19_1457099_G_A        APC2     O95996       O95996-1   Val355Ile   \n",
       "329558    1_16992363_G_A     ATP13A2     Q9NQ11       Q9NQ11-1   Pro629Ser   \n",
       "329559   16_89553052_C_G        SPG7     Q9UQ90       Q9UQ90-1   Thr618Ser   \n",
       "\n",
       "       pathogenicity                                          phenotype  \\\n",
       "0          uncertain                          galloway mowat syndrome 1   \n",
       "1         pathogenic  mitochondrial complex 1 deficiency, nuclear ty...   \n",
       "2          uncertain  inborn genetic diseases | mitochondrial comple...   \n",
       "3        conflicting  hemochromatosis type 1 | hereditary hemochroma...   \n",
       "4          uncertain  hemochromatosis type 1 | hereditary hemochroma...   \n",
       "...              ...                                                ...   \n",
       "329555    pathogenic                            inborn genetic diseases   \n",
       "329556    pathogenic                                   sotos syndrome 3   \n",
       "329557    pathogenic                                   sotos syndrome 3   \n",
       "329558     uncertain                               spastic tetraparesis   \n",
       "329559     uncertain                               spastic tetraparesis   \n",
       "\n",
       "        ndd_phe  \n",
       "0             1  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "329555        0  \n",
       "329556        1  \n",
       "329557        1  \n",
       "329558        0  \n",
       "329559        0  \n",
       "\n",
       "[329560 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # One can skip all these steps and just load the already processed dataset:\n",
    "# clinvar_m = pd.read_csv('output/clinvar_filtered_kristina_milena.csv', header=0, sep='\\t')\n",
    "# # And go to the merging DDD and Clinvar part.\n",
    "\n",
    "# # load unfiltered clinvar\n",
    "# clinvar = pd.read_csv(find_file('kristina_variant_summary.txt'), sep='\\t', header=0)\n",
    "# # clean it up a little\n",
    "# clinvar = clinvar[clinvar['Assembly'] == 'GRCh38']\n",
    "# clinvar = clinvar[['#AlleleID', 'VariationID', 'GeneSymbol', 'Chromosome', 'Start', 'ReferenceAlleleVCF', 'AlternateAlleleVCF']]\n",
    "# clinvar.drop_duplicates(inplace=True)\n",
    "# clinvar.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# # load filtered clinvar:\n",
    "# query = '''select * from kristina_db.ClinVar_filtered as df'''\n",
    "# clinvar_filtered = pd.read_sql_query(query, con=eng)\n",
    "\n",
    "# # merge them:\n",
    "# clinvar['Chromosome'] = [int(i) if str(i).isdigit() else str(i) for i in clinvar['Chromosome']]\n",
    "# clinvar_filtered['Chromosome'] = [int(i) if str(i).isdigit() else str(i) for i in clinvar_filtered['Chromosome']] #I am doing this to have successful merging\n",
    "# clinvar_m = clinvar_filtered.merge(clinvar, how='inner', left_on=['AlleleID','VariationID','Chromosome'], right_on=['#AlleleID','VariationID','Chromosome']) \n",
    "# clinvar_m = clinvar_m[['AlleleID', 'VariationID', 'Chromosome', 'Start', 'ReferenceAlleleVCF','AlternateAlleleVCF', 'GeneSymbol','uni_AC', 'Uniprot_iso', 'aa_change',  'ClinicalSignificance',  'PhenotypeList', 'NDD_phenotype']]\n",
    "\n",
    "# ### clean up the merged dataframe:\n",
    "\n",
    "# # choose and rename columns\n",
    "# clinvar_m.rename(columns={'AlleleID': 'allele_id', 'VariationID':'variation_id','Chromosome':'chromosome', 'Start':'coords','ReferenceAlleleVCF':'ref','AlternateAlleleVCF':'alt','GeneSymbol':'gene_symbol','uni_AC':'uniprot_id','Uniprot_iso':'uniprot_iso_id', 'ClinicalSignificance':'pathogenicity','PhenotypeList':'phenotype','NDD_phenotype':'ndd_phe'}, inplace=True)\n",
    "# # introduce the composite_id column:\n",
    "# clinvar_m['composite_id'] = ['_'.join([str(i) for i in [a, b, c, d]]) for a, b, c, d in zip(clinvar_m['chromosome'], clinvar_m['coords'], clinvar_m['ref'], clinvar_m['alt'])]\n",
    "# # clean up pathogenicity and phenotype columns:\n",
    "# dictionary = {'Uncertain significance':'uncertain', 'Pathogenic':'pathogenic', 'Conflicting interpretations of pathogenicity':'conflicting', 'Likely pathogenic':'pathogenic', 'Benign':'benign', 'Likely benign':'benign', 'Pathogenic/Likely pathogenic':'pathogenic', 'Benign/Likely benign':'benign'}\n",
    "# for k, v in dictionary.items():\n",
    "#     clinvar_m['pathogenicity'] = clinvar_m['pathogenicity'].str.replace(k, v)\n",
    "# dictionary = {'pathogenic/pathogenic':'pathogenic', 'benign/benign':'benign'}\n",
    "# for k, v in dictionary.items():\n",
    "#     clinvar_m['pathogenicity'] = clinvar_m['pathogenicity'].str.replace(k, v)\n",
    "# clinvar_m['phenotype']  =[i.lower().replace('|', ' | ').replace('-', '').replace(' | not provided', '').replace(' | not specified', '').replace('not provided | ', '').replace('not specified | ', '').replace('not provided, ', '').replace(', not provided', '') for i in clinvar_m['phenotype']]\n",
    "# clinvar_m['phenotype'] = clinvar_m['phenotype'].replace({'not provided':None}) #change to proper None values\n",
    "# clinvar_m['phenotype'] = clinvar_m['phenotype'].replace({'not specified':None}) #change to proper None values\n",
    "# # filter out Ter mutations: \n",
    "# clinvar_m = clinvar_m[~(clinvar_m['aa_change'].str.contains('Ter'))]\n",
    "# # reorder the columns:\n",
    "# clinvar_m = clinvar_m[clinvar_m.columns.tolist()[:6] + ['composite_id'] + clinvar_m.columns.tolist()[6:-1]]\n",
    "# clinvar_m.drop_duplicates(inplace=True)\n",
    "# clinvar_m.reset_index(inplace=True, drop=True)\n",
    "# clinvar_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6a7683e-6bc3-4c79-99f6-f6801c712d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenotype\n"
     ]
    }
   ],
   "source": [
    "# #check for NaN values:\n",
    "# col_list = clinvar_m.columns.tolist()\n",
    "# for col in col_list:\n",
    "#     if ((clinvar_m[col].isna()).any()).any():\n",
    "#         print(col) \n",
    "# # phenotype contains NaN values but that's okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22931504-c7fa-4dd6-8bcf-308be7514d9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allele_id</th>\n",
       "      <th>variation_id</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>coords</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>composite_id</th>\n",
       "      <th>gene_symbol</th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>uniprot_iso_id</th>\n",
       "      <th>aa_change</th>\n",
       "      <th>pathogenicity</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>ndd_phe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [allele_id, variation_id, chromosome, coords, ref, alt, composite_id, gene_symbol, uniprot_id, uniprot_iso_id, aa_change, pathogenicity, phenotype, ndd_phe]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # check redundancy in clinvar_m:\n",
    "# clinvar_m1 = clinvar_m.copy(deep=True)\n",
    "# clinvar_m1 = clinvar_m1.groupby(['chromosome','coords','ref','alt', 'composite_id'], as_index=False).agg({i: lambda x: x.tolist() for i in clinvar_m1.columns.tolist()[0:2] + clinvar_m1.columns.tolist()[7:]})\n",
    "\n",
    "# #those that were single values, I don't want them in a list\n",
    "# list_columns = clinvar_m1.columns.tolist()[5:] \n",
    "# for column in list_columns:\n",
    "#     clinvar_m1[column] = [list(set(i)) if len(set(i)) > 1 else ''.join([str(a) for a in i]) for i in clinvar_m1[column].values]\n",
    "    \n",
    "# clinvar_m1['allele_id'] = clinvar_m1['allele_id'].astype(int)\n",
    "# clinvar_m1['variation_id'] = clinvar_m1['variation_id'].astype(int)\n",
    "# clinvar_m1['ndd_phe'] = clinvar_m1['ndd_phe'].astype(int)\n",
    "\n",
    "# clinvar_m1[clinvar_m1['ndd_phe'].apply(lambda x: type(x) == list)] #none of the columns have redundancy! that's good - that means there are no cases where one gene is coding for more than one uniprot or where one mutation is falling into 2 genes and so on, that's also fine but it complicates the situation a little\n",
    "\n",
    "# # check redundancy, but for allele_id, variation_id and chromosome:\n",
    "# clinvar_m2 = clinvar_m.copy(deep=True)\n",
    "# clinvar_m2 = clinvar_m2.groupby(['allele_id','variation_id','chromosome'], as_index=False).agg({i: lambda x: x.tolist() for i in clinvar_m2.columns.tolist()[3:]})\n",
    "\n",
    "# list_columns = clinvar_m2.columns.tolist()[3:] \n",
    "# for column in list_columns:\n",
    "#     clinvar_m2[column] = [list(set(i)) if len(set(i)) > 1 else ''.join([str(a) for a in i]) for i in clinvar_m2[column].values]\n",
    "    \n",
    "# clinvar_m2['ndd_phe'] = clinvar_m2['ndd_phe'].astype(int) \n",
    "# clinvar_m2[clinvar_m2['aa_change'].apply(lambda x: type(x) == list)] #also no redundancy, good!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a5c94c4-45f4-4f56-8ba1-e3bee2498156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# # Now, we did compare reference amino acid to swissprot sequences but we did not compare to John's version, so I will do that:\n",
    "\n",
    "# #I need to prepare clinvar_m dataset first by introducing some columns\n",
    "# clinvar_m.reset_index(inplace=True, drop=True)\n",
    "# clinvar_m['aa_ref'] = [i[:3] for i in clinvar_m['aa_change']]\n",
    "# clinvar_m['aa_alt'] = [i[-3:] for i in clinvar_m['aa_change']]\n",
    "# clinvar_m['aa_pos'] = [int(''.join([a for a in i if a.isdigit()])) for i in clinvar_m['aa_change']]\n",
    "# clinvar_m['aa_ref_short'] = clinvar_m['aa_ref'] \n",
    "# clinvar_m['aa_alt_short'] = clinvar_m['aa_alt']\n",
    "# AA_dict = {'Phe':'F','Leu':'L','Ser':'S','Tyr':'Y','Cys':'C','Trp':'W','Pro':'P','His':'H','Gln':'Q','Arg':'R','Ile':'I','Met':'M','Thr':'T','Asn':'N','Lys':'K','Val':'V','Ala':'A','Asp':'D','Glu':'E','Gly':'G','Ter':'*'}\n",
    "# clinvar_m['aa_ref_short'] = [AA_dict.get(i) for i in clinvar_m['aa_ref_short']]\n",
    "# clinvar_m['aa_alt_short'] = [AA_dict.get(i) for i in clinvar_m['aa_alt_short']]\n",
    "\n",
    "# # loading John's dataset\n",
    "# query = '''select * from chopyan_db.uniprot_id_sequence as df'''\n",
    "# john_seq = pd.read_sql_query(query, con=eng)\n",
    "\n",
    "# compare_ref_aa = clinvar_m.merge(john_seq, how='inner', on='uniprot_id')\n",
    "# compare_ref_aa = compare_ref_aa[['composite_id','uniprot_id','aa_ref_short','aa_ref','aa_pos','aa_alt_short','aa_alt', 'aa_change','sequence']]\n",
    "# compare_ref_aa['length'] = [len(i) for i in compare_ref_aa['sequence'].values]\n",
    "\n",
    "# print(len(compare_ref_aa[compare_ref_aa['aa_pos'] > compare_ref_aa['length']])) #it's either smaller or equal, good!\n",
    "\n",
    "# #compare the actual sequences:\n",
    "# compare_ref_aa['swiss_prot_ref_aa'] = [seq[pos-1] for seq, pos in zip(compare_ref_aa['sequence'].values, compare_ref_aa['aa_pos'].values)]\n",
    "# print(len(compare_ref_aa[compare_ref_aa['aa_ref_short'] != compare_ref_aa['swiss_prot_ref_aa']])) #no mismatches, great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53cf35c1-739d-4f1d-9940-dc0ec31f8f02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # I think I also want to run NDD annotation on this again, because I did it a bit differently from Kristina:\n",
    "\n",
    "# ### I already made it lowercase, removed -, changed | into | with spaces around it. I also checked NaN values and there are None in this column:\n",
    "\n",
    "# #preparing human phenotype ontology (HPO) list of NDD phenotypes and keyword search data\n",
    "# #load HPO\n",
    "# hpo_ndds = pd.read_excel(find_file('HPO_NDDs.xlsx'), header=0)\n",
    "\n",
    "# #lower string, replace '-', and '|', and create a single string:\n",
    "# hpo_ndds['DISEASE_NAME'] = [i.lower() for i in hpo_ndds['DISEASE_NAME']]\n",
    "# hpo_ndds['DISEASE_NAME'] = hpo_ndds['DISEASE_NAME'].str.replace('-', ' ')\n",
    "# hpo_string_data = ' | '.join([i for i in hpo_ndds['DISEASE_NAME']])\n",
    "# filpat = r\",? ?(Autosomal|Somatic) ?(Dominant|Recessive)? ?\\d*|,? ?((Type)? \\d\\w?|Type \\w{2}) ?\"\n",
    "# hpo = pd.DataFrame(hpo_string_data.split(' | '))\n",
    "# hpo.rename(columns={0:'phenotype'}, inplace=True)\n",
    "# hpo.phenotype = hpo.phenotype.str.replace(filpat, \"\", flags = re.IGNORECASE, regex = True)\n",
    "# hpo_string_data = ' | '.join([i for i in hpo['phenotype']])\n",
    "\n",
    "# #prepare keyword search string:\n",
    "# keyword_search = ' | '.join(['neurodevelopment', 'learning disability', 'cognitive impairment', 'mental retardation', 'intellectual disability', 'autism', 'autistic', 'epilepsy', 'epileptic', 'developmental delay', 'delayed development'])\n",
    "# #learning disability is a synonym of intellectual disability, but for example learning difficulties can be referring to something else, like dyslexia\n",
    "# #cognitive impairment is also a synonym of intellectual disability\n",
    "# #I put neurodevelopment instead of neuro because neuro will also include neuropathies and so on\n",
    "\n",
    "# clinvar_m['hpo'] = clinvar_m['phenotype'] #had to do this because the ndd_annotation function is written for hpo and phenotype columns\n",
    "\n",
    "# def ndd_annotation(dataset, comparison_string, string_name):\n",
    "#     '''\n",
    "#     Annotate phenotypes as NDD associated or not, based on a list of NDD phenotypes\n",
    "#     dataset -> df; the dataset which contains 'phenotype' column which lists phenotypes associated with each variant, and 'hpo' column which lists hpo identifiers for those phenotypes\n",
    "#     comparison_string -> str; string which contains a list of NDD phenotypes separated with a |; I used either a list of NDD phenotypes provided by the HPO ontology or the keyword search list I built myself\n",
    "#     string_name -> str; name of the comparison_string, so that I can change the values in the corresponding columns\n",
    "    \n",
    "#     Returns a dataframe with 3 additional columns: one which lists phenotypes which were found to be NDD-associated, second which lists their corresponding HPO identifiers and the last one which says True\n",
    "#     if at least one of the phenotypes in at least one of the patients were found to be NDD-associated. Also, I did the string matching both ways - if the phenotype in the phenotype column is in the\n",
    "#     string and also if elements of the string are matching to one of the phenotypes in the phenotype column. Either way, the phenotypes which were found to be a match are listed in the f'phenotype_ndd_in_{string_name}'\n",
    "#     column and those are the phenotypes that are in the phenotype column (they are not taken from the string).\n",
    "#     '''\n",
    "    \n",
    "#     dataset[f'phenotype_ndd_in_{string_name}'] = False\n",
    "#     dataset[f'hpo_ndd_in_{string_name}'] = False\n",
    "#     dataset[f'ndd_in_{string_name}'] = False\n",
    "    \n",
    "#     dataset[f'phenotype_ndd_in_{string_name}'] = dataset[f'phenotype_ndd_in_{string_name}'].astype(dtype='object') \n",
    "#     dataset[f'hpo_ndd_in_{string_name}'] = dataset[f'phenotype_ndd_in_{string_name}'].astype(dtype='object')\n",
    "#     dataset[f'ndd_in_{string_name}'] = dataset[f'phenotype_ndd_in_{string_name}'].astype(dtype='object')\n",
    "    \n",
    "#     for n, (phe, hpo) in enumerate(zip(dataset['phenotype'].values, dataset['hpo'].values)):\n",
    "#         if n % 10000 == 0:\n",
    "#             print('a 10 000 done')\n",
    "#         if type(phe) != type(hpo): #I expect them to be same type and if this is not the case, I want to be alarmed\n",
    "#             print('alarm')\n",
    "#         if dataset.loc[n, 'phenotype'] == None:\n",
    "#             dataset.at[n, f'phenotype_ndd_in_{string_name}'] = None\n",
    "#             dataset.at[n, f'hpo_ndd_in_{string_name}'] = None #and the third column will say false!\n",
    "#         comparison_list = list(set(comparison_string.split(' | '))) # hpo string may have some duplicates because it's basically a tree!\n",
    "#         if type(dataset.at[n, 'phenotype']) == str:\n",
    "#             phe_list = phe.split(' | ') #this is now a list of phenotypes\n",
    "#             hpo_list = hpo.split(' | ') #I defined it here because I will use it in the first and the second if statement\n",
    "#             if True in [True for i in phe_list if i in comparison_string]:\n",
    "#                 dataset.at[n, f'ndd_in_{string_name}'] = True\n",
    "#                 dataset.at[n, f'phenotype_ndd_in_{string_name}'] = ' | '.join([i for i in phe_list if i in comparison_string]) #if any of them are in the list\n",
    "#                 get_indices = [phe_list.index(i) for i in phe_list if i in comparison_string]\n",
    "#                 dataset.at[n, f'hpo_ndd_in_{string_name}'] = ' | '.join(list(np.array(hpo_list)[get_indices])) #get those exact HPO IDs also !\n",
    "#             ######################\n",
    "#             #now I want to check the other way around\n",
    "#             if True in [True for i in comparison_list if i in phe]:\n",
    "#                 dataset.at[n, f'ndd_in_{string_name}'] = True #again, immediately set to True, so if it's either the previous thing or this thing, I want it to be set to true\n",
    "#                 if True not in [True for i in phe_list if i in comparison_string]: #if the previous statement is not true, then there is no need to concatenate the 2 strings\n",
    "#                     #first let's get a list of matches from the comparison_list\n",
    "#                     list_of_matches = [i for i in comparison_list if i in phe]\n",
    "#                     #now let's get phenotypes which contain these matches!\n",
    "#                     dataset.at[n, f'phenotype_ndd_in_{string_name}'] = ' | '.join(list(OrderedDict.fromkeys([i for i in phe_list for x in list_of_matches if x in i]))) #if one of the elements contains both of the matches, it will be mentioned twice and there is no need for that; for example 'autistic behavior, intellectual disability | skeletal disorder', the first element will appear twice, but this is unlikely #used set\n",
    "#                     get_indices = list(OrderedDict.fromkeys([phe_list.index(i) for i in phe_list for x in list_of_matches if x in i])) #the reason I used ordereddict is because it preserves order!\n",
    "#                     dataset.at[n, f'hpo_ndd_in_{string_name}'] = ' | '.join(list(OrderedDict.fromkeys(list(np.array(hpo_list)[get_indices])))) #get those exact HPO IDs also ! #used set\n",
    "#                 if True in [True for i in phe_list if i in comparison_string]: #if this is a True statement, then I want to concatenate this and the previous value\n",
    "#                     phe_value_1 = ' | '.join([i for i in phe_list if i in comparison_string])\n",
    "#                     get_indices = [phe_list.index(i) for i in phe_list if i in comparison_string]\n",
    "#                     hpo_value_1 = ' | '.join(list(np.array(hpo_list)[get_indices]))\n",
    "#                     #value 2:\n",
    "#                     list_of_matches = [i for i in comparison_list if i in phe]\n",
    "#                     phe_value_2 = ' | '.join(list(OrderedDict.fromkeys([i for i in phe_list for x in list_of_matches if x in i])))\n",
    "#                     get_indices = list(OrderedDict.fromkeys([phe_list.index(i) for i in phe_list for x in list_of_matches if x in i]))\n",
    "#                     hpo_value_2 = ' | '.join(list(OrderedDict.fromkeys(list(np.array(hpo_list)[get_indices]))))\n",
    "#                     #final value:\n",
    "#                     phe_value = phe_value_1 + ' | ' + phe_value_2\n",
    "#                     phe_value = ' | '.join(list(OrderedDict.fromkeys(phe_value.split(' | ')))) #I wanna take a set in that case #I'm afraid this might change the order but let's see, as long as we do the same thing with hpo, should be fine?\n",
    "#                     hpo_value = hpo_value_1 + ' | ' + hpo_value_2\n",
    "#                     hpo_value = ' | '.join(list(OrderedDict.fromkeys(hpo_value.split(' | '))))\n",
    "#                     dataset.at[n, f'phenotype_ndd_in_{string_name}'] = phe_value\n",
    "#                     dataset.at[n, f'hpo_ndd_in_{string_name}'] = hpo_value\n",
    "#             if (True not in [True for i in phe_list if i in comparison_string]) & (True not in [True for i in comparison_list if i in phe]):\n",
    "#                 dataset.at[n, f'phenotype_ndd_in_{string_name}'] = None #if we cannot find matches either way, then we set this to None and the columns will stay 'False'\n",
    "#                 dataset.at[n, f'hpo_ndd_in_{string_name}'] = None\n",
    "#         if type(dataset.at[n, 'phenotype']) == list: #this would be a list of strings\n",
    "#             new_value_phe = []\n",
    "#             new_value_hpo = []\n",
    "#             for phe_string, hpo_string in zip(phe, hpo): #we go through one string first\n",
    "#                 if phe_string == None: #if one of the values is None, which means that the phenotype for one patient is not available and then hpo will also be None\n",
    "#                     pass\n",
    "#                 else: #this is now if it's a string basically\n",
    "#                     phe_list = phe_string.split(' | ') #I gotta define this now for every string of the list, if type(dataset.at[n, 'phenotype']) == list\n",
    "#                     hpo_list = hpo_string.split(' | ')\n",
    "#                     if True in [True for i in phe_list if i in comparison_string]:\n",
    "#                         dataset.at[n, f'ndd_in_{string_name}'] = True\n",
    "#                         new_value_phe = new_value_phe + [i for i in phe_list if i in comparison_string] #I don't want to append a list, then it will be a list of lists\n",
    "#                         get_indices = [phe_list.index(i) for i in phe_list if i in comparison_string]\n",
    "#                         new_value_hpo = new_value_hpo + list(np.array(hpo_list)[get_indices])\n",
    "#                     ######################\n",
    "#                     #now I want to check the other way around\n",
    "#                     #I already defined the comparison list up there\n",
    "#                     if True in [True for i in comparison_list if i in phe_string]:\n",
    "#                         dataset.at[n, f'ndd_in_{string_name}'] = True #again, immediately set to True, so if it's either the previous thing or this thing, I want it to be set to true\n",
    "#                         #first let's get a list of matches from the comparison_list\n",
    "#                         list_of_matches = [i for i in comparison_list if i in phe_string]\n",
    "#                         #now let's get phenotypes which contain these matches!\n",
    "#                         new_value_phe = new_value_phe + list(OrderedDict.fromkeys([i for i in phe_list for x in list_of_matches if x in i]))\n",
    "#                         get_indices = list(OrderedDict.fromkeys([phe_list.index(i) for i in phe_list for x in list_of_matches if x in i]))\n",
    "#                         new_value_hpo = new_value_hpo + list(OrderedDict.fromkeys(list(np.array(hpo_list)[get_indices])))\n",
    "#                     if (True not in [True for i in phe_list if i in comparison_string]) & (True not in [True for i in comparison_list if i in phe_string]):\n",
    "#                         pass\n",
    "#             if new_value_phe == []: #if there are no None values and also if none of the phenotypes match\n",
    "#                 new_value_phe = None\n",
    "#                 new_value_hpo = None\n",
    "#             else:\n",
    "#                 new_value_phe = ' | '.join(list(OrderedDict.fromkeys(new_value_phe))) #so far I was just concatenating strings to the new_value_hpo, but now i WANT\n",
    "#                 new_value_hpo = ' | '.join(list(OrderedDict.fromkeys(new_value_hpo)))\n",
    "#             dataset.at[n, f'phenotype_ndd_in_{string_name}'] = new_value_phe\n",
    "#             dataset.at[n, f'hpo_ndd_in_{string_name}'] = new_value_hpo\n",
    "#     return dataset\n",
    "\n",
    "# # clinvar_m = ndd_annotation(clinvar_m, hpo_string_data, 'hpo')\n",
    "# # clinvar_m = ndd_annotation(clinvar_m, keyword_search, 'keyword_search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6796bc9-d4fa-4901-9e63-49683d9ad950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clinvar_m['ndd_phe_m'] = [1 if (a or b) == True else 0 for a,b in zip(clinvar_m['ndd_in_hpo'], clinvar_m['ndd_in_keyword_search'])]\n",
    "# print(sum(clinvar_m['ndd_phe']))\n",
    "# print(sum(clinvar_m['ndd_phe_m'])) #my search finds a bit more matches, so I will keep this one\n",
    "\n",
    "# keep the columns I think are worth saving in a file:\n",
    "# clinvar_m = clinvar_m[clinvar_m.columns.tolist()[:10] + ['aa_change', 'aa_ref','aa_alt', 'aa_pos', 'aa_ref_short', 'aa_alt_short', 'pathogenicity', 'phenotype', 'phenotype_ndd_in_hpo','ndd_in_hpo','phenotype_ndd_in_keyword_search','ndd_in_keyword_search','ndd_phe_m']]\n",
    "# clinvar_m.to_csv('output/clinvar_filtered_kristina_milena.csv', header=True, sep='\\t', index=False)\n",
    "# clinvar_m = pd.read_csv(find_file('clinvar_filtered_kristina_milena.csv'), sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54ae7f-cc88-41c6-af93-dcbac1e2ee25",
   "metadata": {},
   "source": [
    "# Merging DDD and Clinvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dac07f-e9b4-4884-948a-cf5354437eae",
   "metadata": {},
   "source": [
    "Columns I want to keep in the merged dataset:\n",
    "- allele_id, variation_id\n",
    "- chromosome, coords, ref, alt and composite_id\n",
    "- gene symbol, uniprot_id, aa_change, aa_pos, pathogenicity, ndd_phe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57403795-4d4e-45b4-bf96-afbc668c4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I got this from another notebook, called Clinvar_preprocessing\n",
    "new_clinvar = pd.read_csv(find_file('clinvar_filtered_milena_2023.csv'), sep='\\t', header=0)\n",
    "clinvar_m = new_clinvar.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "089549a9-88de-441e-ae5f-b4a61c462aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('benign', 'uncertain'), ('uncertain', 'pathogenic'), ('pathogenic', 'conflicting'), ('benign', 'conflicting'), ('pathogenic', 'benign'), ('uncertain', 'conflicting'), ('pathogenic', 'uncertain'), ('uncertain', 'benign'), ('benign', 'pathogenic')}\n"
     ]
    }
   ],
   "source": [
    "# clinvar_m = clinvar_m[['allele_id','variation_id','chromosome','coords','ref','alt', 'composite_id', 'gene_symbol', 'uniprot_id', 'aa_change', 'aa_pos', 'pathogenicity', 'ndd_phe']]\n",
    "# clinvar_m.rename(columns={'ndd_phe_m':'ndd_phe'}, inplace=True)\n",
    "\n",
    "ddd['allele_id'] = None\n",
    "ddd['variation_id'] = None\n",
    "ddd.rename(columns={'chr':'chromosome'}, inplace=True) # because sql does not accept chr as the column name, it means character\n",
    "\n",
    "# I first wanted to look at the intersection:\n",
    "m = ddd.merge(clinvar_m, how='inner', on='composite_id') #maybe I could have also merged on aa_change, but I checked and it makes no difference\n",
    "m[m['gene_symbol_x'] != m['gene_symbol_y']] #there are small differences for fused genes, but I would take gene_symbol x from DDD study because it's simplified\n",
    "m[m['aa_change_x'] != m['aa_change_y']] #varmap mapping I used for DDD study is clearly the same as mapping in clinvar !! great !!\n",
    "\n",
    "## there was a conflict for pathogenicity values for 332 rows:\n",
    "combinations = []\n",
    "for a, b in zip(m[m['pathogenicity_x'] != m['pathogenicity_y']]['pathogenicity_x'], m[m['pathogenicity_x'] != m['pathogenicity_y']]['pathogenicity_y']):\n",
    "    combinations.append([a, b])\n",
    "    \n",
    "print(set(tuple(row) for row in combinations)) #these are all the combinations I saw\n",
    "\n",
    "# I want to label this flag in the 'pathogenicity_conflict' column:\n",
    "dataset_conflict_ind = m[(m['pathogenicity_x'] != m['pathogenicity_y']) & (m['pathogenicity_conflict'].isna())][['pathogenicity_x','pathogenicity_y','pathogenicity_conflict']].index\n",
    "both_conflict_ind = m[(m['pathogenicity_x'] != m['pathogenicity_y']) & (m['pathogenicity_conflict'] == 'patient_conflicting')][['pathogenicity_x','pathogenicity_y','pathogenicity_conflict']].index\n",
    "m.loc[dataset_conflict_ind, 'pathogenicity_conflict'] = 'dataset_conflicting'\n",
    "m.loc[both_conflict_ind, 'pathogenicity_conflict'] = 'both_conflicting'\n",
    "\n",
    "#solution:\n",
    "#when it's pathogenic or benign in ddd for example and uncertain in clinvar, I will label it as pathogenic or benign, respectively\n",
    "#when it's the same situation, but with conflicting, I will also label it as pathogenic or benign, because probably the conflict has been resolved, or otherwise if they are not a 100% sure that it's pathogenic or benign, they should label it as uncertain or conflicting\n",
    "#when it's pathogenic in one dataset and benign in another, I will label it as conflicting\n",
    "#when it's uncertain and conflictig, I will label it as conflicting because that is more information, that means in one of the datasets, there is information for both\n",
    "\n",
    "for a, b, ind in (zip(m[m['pathogenicity_x'] != m['pathogenicity_y']]['pathogenicity_x'].values, m[m['pathogenicity_x'] != m['pathogenicity_y']]['pathogenicity_y'].values, m[m['pathogenicity_x'] != m['pathogenicity_y']].index)):\n",
    "    if (((a == 'pathogenic') or (a == 'benign')) and (b == 'uncertain')) or (((b == 'pathogenic') or (b == 'benign')) and (a == 'uncertain')):\n",
    "        new_value = ''.join([i for i in [a, b] if i != 'uncertain'])\n",
    "        m.loc[ind, 'pathogenicity_x'] = new_value\n",
    "        m.loc[ind, 'pathogenicity_y'] = new_value\n",
    "    if (((a == 'pathogenic') or (a == 'benign')) and (b == 'conflicting')) or (((b == 'pathogenic') or (b == 'benign')) and (a == 'conflicting')):\n",
    "        new_value = ''.join([i for i in [a, b] if i != 'conflicting'])\n",
    "        m.loc[ind, 'pathogenicity_x'] = new_value\n",
    "        m.loc[ind, 'pathogenicity_y'] = new_value\n",
    "    if ((a == 'pathogenic') and (b == 'benign')) or ((b == 'pathogenic') and (a == 'benign')):\n",
    "        new_value = 'conflicting'\n",
    "        m.loc[ind, 'pathogenicity_x'] = new_value\n",
    "        m.loc[ind, 'pathogenicity_y'] = new_value\n",
    "    if ((a == 'uncertain') and (b == 'conflicting')) or ((b == 'uncertain') and (a == 'conflicting')):\n",
    "        new_value = 'conflicting'\n",
    "        m.loc[ind, 'pathogenicity_x'] = new_value\n",
    "        m.loc[ind, 'pathogenicity_y'] = new_value\n",
    "\n",
    "# now also the ndd_phe column was not always a match, in other words the phenotype provided in clinvar ndd_phe is 0 and in ddd is 1 or the other way around\n",
    "# I looked at those examples, and it's mostly like this when phenotype is 'None' in one of the 2 datasets, so in one of them it might be 1 and in another it might be 0 simply because the phenotype is not provided\n",
    "# I looked for cases where the phenotype is provided in both datasets, and yet, in one of them it might be 0 and in another it might be 1 and this is because either the phenotypes are slightly differently stated: for example for this mutation: 10_102689939_T_C\n",
    "# or the phenotypes provided were quite different\n",
    "m[(m['ndd_phe_x'] == 1) & (m['ndd_phe_y'] == 0)]['composite_id'].unique().tolist()\n",
    "m[(m['ndd_phe_y'] == 1) & (m['ndd_phe_x'] == 0)]['composite_id'].unique().tolist()\n",
    "# clinvar_m[(clinvar_m['composite_id'].isin(m[(m['ndd_phe_x'] == 1) & (m['ndd_phe_y'] == 0)]['composite_id'].unique().tolist())) & ~(clinvar_m['phenotype'].isna())]; #those which are 0 in clinvar and ddd in 1\n",
    "# ddd[(ddd['composite_id'].isin(m[(m['ndd_phe_y'] == 1) & (m['ndd_phe_x'] == 0)]['composite_id'].unique().tolist())) & ~(ddd['phenotype'].isna())];\n",
    "\n",
    "#so I will use or:\n",
    "m['ndd_phe'] = [a or b for a, b in zip(m['ndd_phe_x'], m['ndd_phe_y'])]\n",
    "\n",
    "#choose and rename columns:\n",
    "m = m[['allele_id_y','variation_id_y', 'chromosome_x', 'coords_x', 'ref_x', 'alt_x', 'composite_id', 'gene_symbol_x', 'uniprot_id_x', 'aa_change_x', 'aa_pos_x', 'pathogenicity_x', 'pathogenicity_conflict', 'ndd_phe']]\n",
    "m.rename(columns={'aa_pos_x':'aa_pos', 'allele_id_y':'allele_id','chromosome_x':'chromosome', 'variation_id_y':'variation_id','coords_x':'coords','ref_x':'ref','alt_x':'alt','gene_symbol_x':'gene_symbol','uniprot_id_x':'uniprot_id','aa_change_x':'aa_change','pathogenicity_x':'pathogenicity'}, inplace=True)\n",
    "clinvar_m['pathogenicity_conflict'] = None\n",
    "                  \n",
    "# now the clinvar_m and ddd which do not overlap (parts outside of the intersection, and in the end I will concatenate three datasets)\n",
    "col_list = m.columns.tolist()\n",
    "ddd = ddd[col_list]\n",
    "clinvar_m = clinvar_m[col_list]\n",
    "\n",
    "ddd = ddd[~(ddd['composite_id'].isin(m['composite_id'].unique().tolist()))]\n",
    "clinvar_m = clinvar_m[~(clinvar_m['composite_id'].isin(m['composite_id'].unique().tolist()))]\n",
    "ddd['ddd'] = 1\n",
    "ddd['clinvar'] = 0\n",
    "clinvar_m['ddd'] = 0\n",
    "clinvar_m['clinvar'] = 1\n",
    "m['ddd'] = 1\n",
    "m['clinvar'] = 1\n",
    "\n",
    "mutation_data = pd.concat([clinvar_m, ddd, m], axis=0)\n",
    "\n",
    "mutation_data['ndd_phe'] = mutation_data['ndd_phe'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8098e41-2701-472f-be48-d3f8284446f1",
   "metadata": {},
   "source": [
    "## Investigating NaN values and redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5be5ab66-2d53-46cc-b217-8df6ac8a858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allele_id\n",
      "variation_id\n",
      "pathogenicity_conflict\n"
     ]
    }
   ],
   "source": [
    "max([len(str(i)) for i in mutation_data['gene_symbol']]) # here I noticed that within clinvar there are values like: covers 10 genes, none of which show dosage sensitivity, which I don't really know what it means and since uniprot was provided, I just replaced this with a proper gene symbol\n",
    "mutation_data.loc[mutation_data['uniprot_id'] == 'P22309', 'gene_symbol'] = 'UGT1A1' # replaced this with manually searched gene symbol\n",
    "#however, in clinvar there are still values where genes are separated by ';' and one of them is really affected by the mutation according to the locations, but another one is not necessarily affected, so be aware of that - there are 712 cases like this\n",
    "#for now I didn't do anything about this because for overlapping with John's predictor, we actually need uniprots and not gene symbols!\n",
    "\n",
    "#check for NaN values:\n",
    "col_list = mutation_data.columns.tolist()\n",
    "for col in col_list:\n",
    "    if ((mutation_data[col].isna()).any()).any():\n",
    "        print(col) \n",
    "#none of the columns contain NaN values\n",
    "\n",
    "#uniprot was important for us not to have this, because we used that for the overlap !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbe666-a5e2-4040-b0cd-d588951d0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I thought there is redundancy in DDD because one mutation can be found in 2 genes and 2 uniprots and so on, but if you use composite_id + aa_change, there is no redundancy\n",
    "# In clinvar there is this redundancy because the identifier does not include anything on the protein level, but it's kept in one row, separated by ; - in 712 rows\n",
    "\n",
    "# So to answer the question if one mutation is one row - for clinvar yes because other information is concatenated.\n",
    "# In ddd if you just use composite ID (look at the mutation from the gene level), then no, but if you include aa_change, then yes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2a546db-f7e7-4ef7-b519-029a0c847798",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-42febd85f0cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmut_data1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmut_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmut_data1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmut_data1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'composite_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aa_change'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmut_data1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'composite_id'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'aa_change'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmut_data1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmut_data1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'composite_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'aa_change'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmut_data1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlist_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmut_data1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupByApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;31m# we require a list, but not a 'str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0;31m# key used for column selection and output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             results = {\n\u001b[0m\u001b[1;32m    505\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             }\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0;31m# key used for column selection and output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             results = {\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m             }\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnkeys\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_agg_general\u001b[0;34m(self, func, raise_on_typeerror, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1680\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m                 \u001b[0;31m# if this function is invalid for this dtype, we will ignore it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mraise_on_typeerror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36magg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_series_pure_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0mnpvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0msplitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_splitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_chop\u001b[0;34m(self, sdata, slice_obj)\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0;31m# fastpath equivalent to `sdata.iloc[slice_obj]`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m         \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"groupby\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mget_slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m         \u001b[0mblk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2047\u001b[0m         \u001b[0mbp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockPlacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;34m\"\"\"return a slice of my values\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Does one clinvar ID correspond to one DDD id? Yes.\n",
    "\n",
    "# for those cases where allele id and variation id is not NaN, I wanted to check if one composite ID-aa change combination corresponds to one allele and var. ID and chromosome\n",
    "mut_data = mutation_data[~(mutation_data['allele_id'].isna()) & ~(mutation_data['variation_id'].isna())]\n",
    "\n",
    "mut_data1 = mut_data.copy(deep=True)\n",
    "mut_data1 = mut_data1[['composite_id', 'aa_change'] + [i for i in mut_data1.columns.tolist() if (i != 'composite_id') and (i != 'aa_change')]]\n",
    "mut_data1 = mut_data1.groupby(['composite_id','aa_change'], as_index=False).agg({i: lambda x: x.tolist() for i in mut_data1.columns.tolist()[2:]})\n",
    "\n",
    "list_columns = mut_data1.columns.tolist()[2:] \n",
    "for column in list_columns:\n",
    "    mut_data1[column] = [list(set(i)) if len(set(i)) > 1 else ''.join([str(a) for a in i]) for i in mut_data1[column].values]\n",
    "\n",
    "mut_data1[mut_data1['allele_id'].apply(lambda x: type(x) == list)] # there is no redundancy\n",
    "\n",
    "# and to check the other way around too:\n",
    "mut_data1 = mut_data.copy(deep=True)\n",
    "mut_data1 = mut_data1[['allele_id', 'variation_id', 'chromosome'] + [i for i in mut_data1.columns.tolist() if (i != 'allele_id') and (i != 'variation_id') and (i != 'chromosome')]]\n",
    "mut_data1 = mut_data1.groupby(['allele_id','variation_id', 'chromosome'], as_index=False).agg({i: lambda x: x.tolist() for i in mut_data1.columns.tolist()[3:]})\n",
    "\n",
    "list_columns = mut_data1.columns.tolist()[3:] \n",
    "for column in list_columns:\n",
    "    mut_data1[column] = [list(set(i)) if len(set(i)) > 1 else ''.join([str(a) for a in i]) for i in mut_data1[column].values]\n",
    "\n",
    "mut_data1[mut_data1['composite_id'].apply(lambda x: type(x) == list)] # there is no redundancy\n",
    "\n",
    "# a simpler way to do this would be but I wanted to check both ways, just to be on the safe side\n",
    "mut_data = mut_data[~(mut_data['allele_id'].isna()) & ~(mut_data['variation_id'].isna())]\n",
    "len(mut_data[['allele_id','variation_id','chromosome']].drop_duplicates()) == len(mut_data[['composite_id','aa_change']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae8ecf-2795-4d1a-938a-8f9858d08f39",
   "metadata": {},
   "source": [
    "## Upload to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea27ba06-6a2b-44b8-b533-182570389357",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_v1 = pd.read_csv(find_file('clinvar_filtered_kristina_milena.csv'), sep='\\t', header=0)\n",
    "mutation_data['clinvar_version'] = None\n",
    "mutation_data.loc[mutation_data['composite_id'].isin(clinvar_v1['composite_id'].tolist()), 'clinvar_version'] = 'v1'\n",
    "mutation_data.loc[~mutation_data['composite_id'].isin(clinvar_v1['composite_id'].tolist()), 'clinvar_version'] = 'v2'\n",
    "mutation_data.loc[mutation_data['clinvar'] == 0, 'clinvar_version'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f449496-93a9-401c-a02e-c7ee3e0ea74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREATE TABLE `DDD_and_clinvar_mutations_2023_release` (\n",
    "#    `allele_id` int(8) DEFAULT NULL,\n",
    "#    `variation_id` int(8) DEFAULT NULL,\n",
    "#    `chromosome` varchar(2) NOT NULL,\n",
    "#    `coords` int(10) NOT NULL,\n",
    "#    `ref` text(1) NOT NULL,\n",
    "#    `alt` text(1) NOT NULL,\n",
    "#    `composite_id` varchar(18) NOT NULL,\n",
    "#    `gene_symbol` varchar(67) NOT NULL,\n",
    "#    `uniprot_id` varchar(11) NOT NULL,\n",
    "#    `aa_change` varchar(12) NOT NULL,\n",
    "#    `aa_pos` int(6) NOT NULL,\n",
    "#    `pathogenicity` text(12) NOT NULL,\n",
    "#    `pathogenicity_conflict` text(21) DEFAULT NULL,\n",
    "#    `ndd_phe` int(1) NOT NULL,\n",
    "#    `ddd` int(1) NOT NULL,\n",
    "#    `clinvar` int(1) NOT NULL,\n",
    "#    `clinvar_version` varchar(3) DEFAULT NULL,\n",
    "#    PRIMARY KEY (`composite_id`,`aa_change`)\n",
    "#  ) ENGINE=MyISAM DEFAULT CHARSET=utf8mb4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9a76f32-3a0d-45fe-bd59-5e57d96cbf58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mutation_data.reset_index(inplace=True, drop=True) \n",
    "# # make sure NaN values are None\n",
    "\n",
    "connect = db_utils.get_connection()\n",
    "cursor = connect.cursor()\n",
    "\n",
    "db_table = 'milena_db.DDD_and_clinvar_mutations_2023_release'\n",
    "query = \"\"\"insert into %s \n",
    "        (allele_id, variation_id, chromosome, coords, ref, alt, composite_id, gene_symbol, uniprot_id, aa_change, aa_pos, pathogenicity, pathogenicity_conflict, ndd_phe, ddd, clinvar, clinvar_version)\n",
    "        values (%%s, %%s, %%s, %%s, %%s, %%s, %%s, %%s, %%s, %%s, %%s, %%s, %%s, %%s, %%s, %%s, %%s)\"\"\" % (db_table)\n",
    "\n",
    "for i in range(mutation_data.shape[0]):\n",
    "    cursor.execute(query, tuple(mutation_data.loc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47772259-3177-455a-8f6a-bb0a1277f19c",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dde74d9c-af07-41bc-85ea-2eae11135c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of DDD and clinvar mutations\n",
    "\n",
    "out = venn2(subsets=(20000, 328149, 1411), set_labels=['DDD', 'ClinVar'])\n",
    "\n",
    "for idx, subset in enumerate(out.subset_labels):\n",
    "    out.subset_labels[idx].set_visible(False)\n",
    "    \n",
    "out.get_patch_by_id('01').set_color('#3D3D3D')\n",
    "out.get_patch_by_id('01').set_edgecolor('black')\n",
    "\n",
    "out.get_patch_by_id('11').set_color('black')\n",
    "out.get_patch_by_id('11').set_edgecolor('black')\n",
    "out.get_patch_by_id('11').set_alpha(0.7)\n",
    "\n",
    "out.get_patch_by_id('10').set_color('#11FF00')\n",
    "out.get_patch_by_id('10').set_edgecolor('black')\n",
    "\n",
    "plt.savefig('output/plots/venn_ddd_clinvar_intersection1.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46aac2fb-d65f-4c52-be84-88d3873448ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the proportion of pathogenic mutations\n",
    "\n",
    "out = venn2(subsets=(0.3129, 0.09825, 0.55492), set_labels=['DDD', 'ClinVar'])\n",
    "\n",
    "for idx, subset in enumerate(out.subset_labels):\n",
    "    out.subset_labels[idx].set_visible(False)\n",
    "    \n",
    "out.get_patch_by_id('01').set_color('#3D3D3D')\n",
    "out.get_patch_by_id('01').set_edgecolor('black')\n",
    "\n",
    "out.get_patch_by_id('11').set_color('black')\n",
    "out.get_patch_by_id('11').set_edgecolor('black')\n",
    "out.get_patch_by_id('11').set_alpha(0.7)\n",
    "\n",
    "out.get_patch_by_id('10').set_color('#11FF00')\n",
    "out.get_patch_by_id('10').set_edgecolor('black')\n",
    "\n",
    "plt.savefig('output/plots/venn_ddd_clinvar_intersection2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18e28a4f-2bb6-4106-912a-ef413ebef55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the proportion of NDD mutations\n",
    "out = venn2(subsets=(3139/(3139+941), 123876/(123876+204273), 1298/(1298+113)), set_labels=['DDD', 'ClinVar'])\n",
    "\n",
    "for idx, subset in enumerate(out.subset_labels):\n",
    "    out.subset_labels[idx].set_visible(False)\n",
    "    \n",
    "out.get_patch_by_id('01').set_color('#3D3D3D')\n",
    "out.get_patch_by_id('01').set_edgecolor('black')\n",
    "\n",
    "out.get_patch_by_id('11').set_color('black')\n",
    "out.get_patch_by_id('11').set_edgecolor('black')\n",
    "out.get_patch_by_id('11').set_alpha(0.7)\n",
    "\n",
    "out.get_patch_by_id('10').set_color('#11FF00')\n",
    "out.get_patch_by_id('10').set_edgecolor('black')\n",
    "\n",
    "plt.savefig('output/plots/venn_ddd_clinvar_intersection3.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be1b3caf-2a4c-4e22-822f-6b1c5325f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = list(reversed(['VUS', 'benign', 'pathogenic', 'conflicting']))\n",
    " \n",
    "# getting values against each value of y\n",
    "x = [240487, 38933, 34303, 19917]\n",
    "x.reverse()\n",
    "plt.barh(y, x, color=['#FFD321','#DF8B88','#88A8DF','#727272'])\n",
    " \n",
    "# setting label of x-axis\n",
    "plt.xlabel(\"%\") \n",
    "plt.title(\"Pathogenicity of DDD and ClinVar mutations\")\n",
    "\n",
    "plt.savefig('output/plots/clinical_interpretation.jpeg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
